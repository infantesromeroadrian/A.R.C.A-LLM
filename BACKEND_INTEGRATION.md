# üîó Gu√≠a de Integraci√≥n Backend A.R.C.A-LLM

## üì¶ Repositorios

### Backend
- **Repo**: https://github.com/infantesromeroadrian/A.R.C.A-LLM
- **Local**: `../backend/` (o `../A.R.C.A-LLM/` si est√° en ese directorio)
- **Puerto**: 8000
- **Tecnolog√≠a**: Python + FastAPI

### Frontend
- **Repo**: https://github.com/nacho995/msmk-voice-assistant
- **Local**: `./` (este directorio - frontend/)
- **Puerto**: 3000
- **Tecnolog√≠a**: HTML + CSS + JavaScript puro

## üöÄ Ejecutar Ambos Servicios

### Terminal 1: Backend (Python)

```bash
# Opci√≥n 1: Con Docker
cd ../backend  # o cd ../A.R.C.A-LLM si est√° ah√≠
docker-compose up

# Opci√≥n 2: Python directo (sin Docker)
cd ../backend  # o cd ../A.R.C.A-LLM si est√° ah√≠
python -m venv arca-venv

# Windows
arca-venv\Scripts\activate

# macOS/Linux
source arca-venv/bin/activate

pip install -r requirements.txt
python run_arca.py
```

### Terminal 2: Frontend

```bash
# Desde este directorio (frontend/)
cd frontend

# Opci√≥n 1: Con npm (recomendado)
npm install  # Solo la primera vez
npm start

# Opci√≥n 2: Con Python (sin npm)
python3 -m http.server 3000

# Opci√≥n 3: Con npx (sin instalar)
npx http-server -p 3000
```

## ‚úÖ Verificar que Todo Funciona

### 1. Health Check del Backend

```bash
curl http://localhost:8000/api/health
```

Debe retornar:
```json
{
  "status": "healthy",
  "service": "A.R.C.A LLM Voice Assistant"
}
```

### 2. Abrir Frontend

Abre tu navegador en: **http://localhost:3000**

### 3. Probar Integraci√≥n

1. Abre DevTools (F12)
2. Click en el orbe
3. Hablar: "Hola, c√≥mo est√°s?"
4. Click de nuevo para enviar
5. Ver en Console:
   - Usuario: "Hola, c√≥mo est√°s?"
   - A.R.C.A: "[respuesta del LLM]"

## üìä Flujo Completo

```
[Usuario click orbe]
    ‚Üì
[Captura audio con MediaRecorder]
    ‚Üì
[Usuario click de nuevo]
    ‚Üì
[POST audio ‚Üí http://localhost:8000/api/voice/process]
    ‚Üì
[Backend: STT ‚Üí LLM ‚Üí TTS]
    ‚Üì
[Response: audio WAV + headers con texto]
    ‚Üì
[Frontend: Reproduce audio + Anima orbe]
    ‚Üì
[Audio termina ‚Üí Orbe se desactiva]
```

## üîß Variables de Configuraci√≥n

### Frontend
El backend est√° configurado en `js/backend-integration.js`:

```javascript
const CONFIG = {
    BACKEND_URL: 'http://localhost:8000',
    AUDIO_FORMAT: 'audio/webm',
    MIN_RECORDING_TIME: 500, // ms
    MAX_RECORDING_TIME: 30000, // ms
    RETRY_ATTEMPTS: 3
};
```

### Backend
Ver archivo `.env` en `../backend/` (o `../A.R.C.A-LLM/`):

```env
LM_STUDIO_URL=http://127.0.0.1:1234/v1
LM_STUDIO_MODEL=qwen/qwen3-4b-2507
WHISPER_MODEL=tiny
API_PORT=8000
CORS_ORIGINS=["http://localhost:3000"]
```

## üêõ Troubleshooting

### Backend no inicia
- Verifica que Python 3.8+ est√© instalado
- Revisa que LM Studio est√© corriendo (puerto 1234)
- Revisa logs en `../backend/logs/` (o `../A.R.C.A-LLM/logs/`)

### Frontend no conecta con backend
- Verifica que backend est√© en puerto 8000: `curl http://localhost:8000/api/health`
- Revisa CORS en configuraci√≥n del backend
- Revisa consola del navegador (F12) para errores

### Micr√≥fono no funciona
- Permite acceso en configuraci√≥n del navegador
- Usa `localhost` (no `127.0.0.1` o IP)
- Verifica permisos del sistema operativo

## üìö M√°s Informaci√≥n

- **Backend API Docs**: http://localhost:8000/docs (cuando backend est√© corriendo)
- **Backend Repo**: https://github.com/infantesromeroadrian/A.R.C.A-LLM

