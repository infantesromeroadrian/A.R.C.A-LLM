# üê≥ A.R.C.A LLM - Setup con Docker

## üöÄ Inicio R√°pido

### 1. Prerequisitos

- **Docker Desktop** instalado y corriendo
- **LM Studio** corriendo en tu m√°quina host en `http://192.168.1.38:1234`
- **Modelo qwen/qwen3-4b-2507** cargado en LM Studio

---

### 2. Iniciar con Docker Compose

```bash
# Construir la imagen (primera vez o despu√©s de cambios)
docker-compose build

# Iniciar el servicio
docker-compose up

# O en modo detached (background)
docker-compose up -d
```

---

### 3. Acceder a la Aplicaci√≥n

Abre tu navegador en: **http://localhost:8000**

---

### 4. Ver Logs

```bash
# Ver logs en tiempo real
docker-compose logs -f

# Ver logs espec√≠ficos del servicio
docker-compose logs -f arca-llm
```

---

### 5. Detener el Servicio

```bash
# Detener (mantiene los contenedores)
docker-compose stop

# Detener y eliminar contenedores
docker-compose down

# Detener, eliminar y limpiar vol√∫menes
docker-compose down -v
```

---

## üîß Configuraci√≥n

### Variables de Entorno

Todas las configuraciones est√°n en `docker-compose.yml` bajo la secci√≥n `environment`:

```yaml
environment:
  # LLM
  LM_STUDIO_URL: "http://host.docker.internal:1234/v1"
  LM_STUDIO_MODEL: "qwen/qwen3-4b-2507"
  
  # Whisper
  WHISPER_MODEL: "tiny"  # tiny, base, small, medium, large
  
  # TTS
  TTS_RATE: "175"
  TTS_VOLUME: "0.9"
```

**Para cambiar configuraci√≥n:**
1. Editar `docker-compose.yml`
2. Reiniciar: `docker-compose restart`

---

## üì¶ Persistencia de Datos

Los modelos descargados se guardan en:
- `./models/hf_cache/` - Modelos Whisper
- `./logs/` - Logs de la aplicaci√≥n

**Estos directorios persisten entre reinicios.**

---

## üîç Troubleshooting

### Problema: No puede conectar con LM Studio

**Soluci√≥n:**
1. Verificar que LM Studio est√© corriendo
2. Verificar que el servidor local est√© en puerto `1234`
3. En Windows/Mac, Docker usa `host.docker.internal` para el host

### Problema: Puerto 8000 ya en uso

**Soluci√≥n:**
Cambiar puerto en `docker-compose.yml`:
```yaml
ports:
  - "8001:8000"  # Usar puerto 8001 en lugar de 8000
```

### Problema: Modelo Whisper descarga lento

**Soluci√≥n:**
Primera vez toma 1-2 minutos. Luego se cachea en `./models/`

### Ver logs de errores

```bash
docker-compose logs --tail=100 arca-llm
```

---

## üõ†Ô∏è Comandos √ötiles

```bash
# Reconstruir imagen (despu√©s de cambios en requirements.txt)
docker-compose build --no-cache

# Reiniciar servicio
docker-compose restart

# Ver estado
docker-compose ps

# Entrar al contenedor
docker-compose exec arca-llm bash

# Ver uso de recursos
docker stats
```

---

## üöÄ Modo Desarrollo

Para desarrollo con hot-reload, el c√≥digo est√° montado como volumen:

```yaml
volumes:
  - ./src:/app/src  # Cambios en c√≥digo se reflejan autom√°ticamente
```

**Uvicorn detecta cambios autom√°ticamente y recarga.**

---

## üìä Recursos del Sistema

**Configuraci√≥n actual:**
- CPU: 2-4 cores
- RAM: 4-8 GB

**Para ajustar:**
Editar en `docker-compose.yml`:
```yaml
deploy:
  resources:
    limits:
      cpus: '2.0'
      memory: 4G
```

---

## ‚úÖ Checklist de Inicio

- [ ] Docker Desktop instalado y corriendo
- [ ] LM Studio corriendo en puerto 1234
- [ ] Modelo Qwen3-8B cargado en LM Studio
- [ ] Puerto 8000 disponible
- [ ] Ejecutar: `docker-compose up`
- [ ] Abrir: http://localhost:8000
- [ ] Probar conversaci√≥n con el micr√≥fono

---

## üéØ Ventajas de Docker

‚úÖ **Sin conflictos de dependencias**  
‚úÖ **Mismo entorno en cualquier m√°quina**  
‚úÖ **F√°cil deploy**  
‚úÖ **Aislamiento completo**  
‚úÖ **Rollback f√°cil**  

---

## üìù Notas

- Primera vez toma 5-10 minutos (descarga imagen Python + dependencias)
- Modelos Whisper se descargan la primera vez (autom√°tico)
- Los logs se guardan en `./logs/`
- Para actualizar c√≥digo: los cambios en `./src/` se reflejan autom√°ticamente

